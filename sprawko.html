<h1 id="usługi-i-aplikacje-internetu-rzeczy---projekt">Usługi i
  aplikacje Internetu Rzeczy - projekt</h1>
<h2 id="kamera-z-czujnikiem-ruchu-połączona-z-aplikacją-mobilną">Kamera
  z czujnikiem ruchu połączona z aplikacją mobilną</h2>
<h4 id="aleksander-pajorski-jan-narożny">Aleksander Pajorski, Jan
  Narożny</h4>
<h3 id="raspberry-pi">1. Raspberry Pi</h3>
<h4 id="wymagane-elementy">1.1 Wymagane elementy</h4>
<ul>
  <li>Raspberry Pi</li>
  <li><a href="https://help.prusa3d.com/pl/article/camera-compatibility-rpi-prusalink_654918">Kompatybilna kamera</a>
  </li>
  <li>Kompatybilny czujnik ruchu PIR</li>
</ul>
<p>Raspberry Pi powinno być zaktualizowane do najnowszej dystrybucji
  Raspbian OS ‘bookworm’. Należy wykonać</p>
<pre><code>sudo apt update &amp;&amp; sudo apt full-upgrade</code></pre>
<p>aby upewnić się że bibloteki potrzebne do obsługi kamery są dostępne
  i aktualne.</p>
<h4 id="podłączenie-kamery-i-czujnika">1.2 Podłączenie kamery i
  czujnika</h4>
<p>Kamerę podączyć należy przy użyciu dedykowanego kabla oraz portu na
  płytce Pi. Kabel musi być dokładnie osadzony, częścią z kontaktami
  skierowany w przeciwnym kierunku niż zatrzask, a sam zatrzask równie
  dociśnięty. Czujnik ruchu podłączyć według poniższego schematu:</p>

<figure>
  <img src="images/pir_wiring.png" alt="Schemat podłączenia czujnika ruchu" width=300>
  <figcaption aria-hidden="true">Schemat podłączenia czujnika ruchu</figcaption>
</figure>

<p>Czujnik ruchu posiada 3 piny: Vcc, Gnd, oraz Out. Powinne być one
  podpisane. Powyższy schemat jest poglądowy ponieważ w zależności od
  użytej wersji płytki ułożenie pinów GPIO może się różnić. Pin Vcc na
  czujniku podłączyć do pinu zasilającego 5V, pin Gnd do analogcznego pinu
  na płytce Pi, a Out do któregokolwiek z pinów GPIO. W tym przypadku
  użyty został pin 4. Do przetestowania podłączenia czujnika ruchu:</p>
<h4 id="stworzenie-python-virtual-environment">1.3 Stworzenie python
  virtual environment</h4>
<pre><code>python3 -m venv venv

# windows:
venv\Scripts\activate

# macOS i linux:
source venv/scripts/activate

pip install -r requirements.txt</code></pre>
<h4 id="weryfiakcja-podłączenia-kamery-i-czunika">1.4 Weryfiakcja
  podłączenia kamery i czunika</h4>
<p>Aby zweryfikować poprawne podłączenie czujnika:</p>
<pre><code>python3 pirTest.py</code></pre>
<p>Zakończyć ctrl+c. Następnie aby zweryfikować podłączenie kamery:</p>
<pre><code>rpicam-still -n -o test.jpg</code></pre>
<h4 id="chmura-azure">1.5 Chmura azure</h4>
<p>Zdjęcia przesyłane są do chmury azure, na którym założony został
  serwis Azure Blob Storage do przetrzymywania danych. Ze strony głownej
  Azure Portal należy wybrać “Create resource” i dodać do swojej grupy
  zasobów “Storage account”.</p>
<div>
  <figure>
    <img src="images/create-blob-storage.png" alt="Utwórz blob storage" width="300" />
    <figcaption aria-hidden="true">Utwórz blob storage</figcaption>
  </figure>
  <p>W tym miejscu trzeba uzupełnić niezbędne pola: nadać nazwę, wybrać
    najbliższy region, primary service może zostać puste, Performance
    ustawić na standard a Redundancy na Locally redundant storage dla
    najniższych kosztów.</p>
  <p>Po utworzeniu tego zasobu należy go otworzyć, z lewego menu wybrać
    opcję Containers, i kliknąć opcję dodania kontenera. Opcje zaawansowane
    na potrzeby tego projektu są zbędne, więc wystarczy nadać mu nazwę i
    wybrać poziom dostępu.</p>
</div>
<div>
  <figure>
    <img src="images/container.png" alt="Container" width="300" />
    <figcaption aria-hidden="true">Container</figcaption>
  </figure>
  <p>Następnie należy przejść do “Access keys” i pamietać o skopiowaniu
    “Connection string” do kodu na raspberry pi (czy jakimkolwiek innym
    urządzeniu, które będzie chciało uzyskać dostęp do tego Blob
    Storage).</p>
</div>
<figure>
  <img src="images/connection-string.png" alt="Connection string" width="500" />
  <figcaption aria-hidden="true">Connection string</figcaption>
</figure>
<h4 id="aplikacja-mobilna">1.6 Aplikacja mobilna</h4>
<p>Aplikacja mobilna napisana została przy użyciu frameworka React
  Native oraz Expo w języku TypeScript. PhotoGallery jest głównym
  komponentem aplikacji. Po jej otwarciu zdjęcia wczytywane są
  automatycznie, lecz nie są automatycznie odświeżane i w przypadku
  nadejścia nowego zdjęcia należy ręcznie odświeżyć stronę przesuwając
  palcem w dół do ukazania się kółka ładowania. Obok zdjęć znajduje się
  data oraz godzina ich utworzenia.</p>

<figure>
  <img src="images/mobile-app.JPG" alt="Mobile app" width="250" />
  <figcaption aria-hidden="true">Aplikacja mobilna</figcaption>
</figure>
<pre><code>import React, { useEffect, useState } from &#39;react&#39;;
import { View, Text, FlatList, Image, ActivityIndicator, StyleSheet } from &#39;react-native&#39;;
import { BlobServiceClient } from &#39;@azure/storage-blob&#39;;

const PhotoGallery = () =&gt; {
  const [photos, setPhotos] = useState&lt;any[]&gt;([]);
  const [loading, setLoading] = useState&lt;boolean&gt;(true);
  const [refreshing, setRefreshing] = useState&lt;boolean&gt;(false);

  const fetchImages = async () =&gt; {
    try {
      setLoading(true);
      const blobServiceClient = new BlobServiceClient(
        &quot;https://name.blob.core.windows.net&quot;);
      const containerClient = blobServiceClient.getContainerClient(&#39;photos&#39;);
  
      const imageDetails: any[] = [];
      for await (const blob of containerClient.listBlobsFlat()) {
        if (blob.name) {
          const blockBlobClient = containerClient.getBlockBlobClient(blob.name);
          const properties = await blockBlobClient.getProperties();
          const lastModified = properties.lastModified;
          const imageUrl = `${containerClient.url}/${blob.name}`;
          imageDetails.push({ imageUrl, lastModified });
        }
      }
  
      const sortedImages = imageDetails.sort((a, b) =&gt; {
        if (a.lastModified &amp;&amp; b.lastModified) {
          return b.lastModified.getTime() - a.lastModified.getTime();
        }
        return 0;
      });
  
      setPhotos(sortedImages);
      setLoading(false);
      setRefreshing(false);
    } catch (error) {
      console.error(&#39;Error fetching images:&#39;, error);
      setLoading(false);
      setRefreshing(false);
    }
  };
  

  useEffect(() =&gt; {
    fetchImages();
  }, []);

  const onRefresh = () =&gt; {
    setRefreshing(true);
    fetchImages();
  };

  if (loading) {
    return (
      &lt;View style={styles.loaderContainer}&gt;
        &lt;ActivityIndicator size=&quot;large&quot; color=&quot;#aaaaaa&quot; /&gt;
      &lt;/View&gt;
    );
  }

  return (
    &lt;FlatList
      style={{ backgroundColor: &quot;#2b2b2b&quot; }}
      data={photos}
      keyExtractor={(item, index) =&gt; index.toString()}
      renderItem={({ item }) =&gt; (
        &lt;View style={styles.itemContainer}&gt;
          &lt;Image source={{ uri: item.imageUrl }} style={styles.image} /&gt;
          &lt;Text style={styles.time}&gt;
            {item.lastModified?.toLocaleString() || &quot;Unknown&quot;}
          &lt;/Text&gt;
        &lt;/View&gt;
      )}
      onRefresh={onRefresh}
      refreshing={refreshing}
    /&gt;
  );
};

const styles = StyleSheet.create({
  loaderContainer: {
    flex: 1,
    justifyContent: &#39;center&#39;,
    alignItems: &#39;center&#39;,
  },
  itemContainer: {
    flexDirection: &#39;row&#39;,
    margin: 10,
    alignItems: &#39;center&#39;,
  },
  image: {
    width: 220,
    height: 200,
    borderRadius: 10,
  },
  time: {
    marginLeft: 10,
    fontSize: 13,
    color: &#39;white&#39;,
    fontWeight: &#39;700&#39;,
  },
});

export default PhotoGallery;</code></pre>
<p>Paczka “<span class="citation" data-cites="azure/storage-blob">@azure/storage-blob</span>” daje gotowe
  API do komunikacji z Azure Blob Storage. Funkcja fetchImages() tworzy
  instancję BlobServiceClient z podanego linku do zasobu oraz pobiera z
  podanego kontenera wszystkie dane. Z każdego pobranego Blob’a następnie
  wyciąga pola związane z URL do zdjęcia (do jego wyświetlania) oraz
  ostatnią modyfikacją (do wyświetlania daty i godziny jego dodania).
  Później zdjęcia są sortowane po dacie dodania tak, żeby jako pierwsze
  wyświetlały się najnowsze zdjęcia i ostatecznie przypisywana jest lista
  struktur <code>{ imageUrl, lastModified }</code>.</p>
<h4 id="kod-raspberry-pi">1.7 Kod Raspberry Pi</h4>
<p>Raspberry Pi obsluguje kamerę, czujnik ruchu oraz wysyłanie zdjęć do
  chmury skryptem Python. Podzielony jest na część konfiguracyją gdzie
  zdefiniowany jest folder lokalny dla wykonanych zdjęć oraz parametry
  Blob Storage, i definicje fukncji do wykonywania i przesyłania
  zdjęć.</p>
<pre><code>from azure.storage.blob import BlobServiceClient
import subprocess
from gpiozero import MotionSensor
from datetime import datetime
import sys

# Configurations
connection_string = &quot;&lt;connection_string&gt;&quot;
container_name = &quot;&lt;container_name&gt;&quot;
image_path = &quot;tmp/&quot;
pir = MotionSensor(4)


def take_pic(blob_name):
    output = image_path + blob_name
    try:
        subprocess.run([&quot;sudo rpicam-still --nopreview -o &quot; + output], check=True, shell=True, stderr=subprocess.STDOUT)
    except subprocess.CalledProcessError as e:
        raise RuntimeError(&quot;command &#39;{}&#39; returned with error (code {}): {}&quot;.format(e.cmd, e.returncode, e.output))


def upload_pic(blob_name):
    src = image_path + blob_name
    try:
        client = BlobServiceClient.from_connection_string(connection_string)
        blob_client = client.get_blob_client(container=container_name, blob=blob_name)

        with open(src, &quot;rb&quot;) as image_file:
            blob_client.upload_blob(image_file)

        print(f&quot;Image uploaded successfully to {container_name}/{blob_name}&quot;)
    except Exception as e:
        print(&quot;Error uploading file: &quot;, e)


def exit_gracefully():
    print(&quot;Interrupt encountered. Exiting...&quot;)
    sys.exit(0)


def main():
    blob_name = &quot;&quot;
    while True:
        pir.wait_for_motion()
        blob_name = &quot;img_&quot; + datetime.now().strftime(&quot;%H:%M:%S&quot;) + &quot;.jpg&quot;
        take_pic(blob_name)
        upload_pic(blob_name)
        pir.wait_for_no_motion()

if __name__ == &#39;__main__&#39;:
    try:
        main()
    except KeyboardInterrupt as e:
        pass
    finally:
        exit_gracefully()</code></pre>
<p>Paczka “azure.storage.blob” zawiera funkcje potrzebne do obsługi
  przesyłania zdjęć do Blob Storage:
  <code>from_connection_string(connectiopn_string)</code> tworzy instancję
  BlobServiceClient według danych zawartych w ‘connection_string’;
  <code>get_blob_client(container, blob)</code> inicjalizuje interakcję
  klienta z zadanym ‘blob-em’, który jest wysyłany do serwera po wywołaniu
  <code>upload_blob(file)</code>. W tym wypadku ‘file’ zawiera lokalną
  ścieżkę do zdjęcia.
</p>
<p>Paczka subprocess jest używana do uruchamiania polecenia
  odpowiedzialnego za wykonanie zdjęcia jako nowego procesu, podobnie jak
  w przypadku wykonania polecenia w wierszu poleceń.</p>
<p>Paczka “gpiozero” dedykowana jest do obsługi GPIO na Raspberry Pi, co
  znacznie ułatwia obsługę urządzeń takich jak czujnik ruchu poprzez
  dostarczenie gotowych definicji klas jak ‘MotionSensor’, zawierających
  wzselkie przydatne funkcje np. <code>pir.wait_for_motion()</code>.</p>
<p>W <code>main()</code> znajduje się główna pętla programu:</p>
<ol type="1">
  <li>jeśli czujnik ruchu wyśle sygnał do zdefiniowanego pinu GPIO:</li>
  <li>wygenerowana zostaje nazwa pliku
    <code>blob_name = "img_&lt;czas_teraz&gt;"</code>
  </li>
  <li>wywołana zostaje fukcja <code>take_pic()</code></li>
  <li>następnie <code>upload_pic()</code></li>
  <li>program czeka na koniec sygnału z czujnika ruchu aby nie wykonał
    zbyt wielu zdjęć tego samego zajścia.</li>
</ol>